---
title: "Introduction to the research functions"
author: "Jingzhi Ding"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Introduction to the research functions}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

## Overview

The package is mainly about the random forest algorithm and the permutation importance measure. In addition, it contains two algorithms for variable selection. The algorithms come from the paper 'Correlation-and-variable-importance (2017)', and the author is Gregorutti.

Functions in this package are mainly used for calculating variable importance in random forests. Two functions are considered, _permudata_(permute a certain variable of a dataframe), _rfpi_(calculate permutation importance of each variable in random forests), _NRFE_(non recursive feature elimination in random forests for variable selection) and _NRFE_(recursive feature elimination in random forests for variable selection).

## Brief introduction

First, let $D_n=\left\{(X_i,Y) \right\},i=1,...,n$ be a learning set of $n$ i.i.d. replications of $(X,Y)$, $X$ can be a vector.

Consider an estimator based on the observation ofa validation sample $\bar D$:
$$\hat R(\hat f,\bar D)=\frac{1}{|\bar D|}\sum_{i:(X_i,Y_i) \in \bar D}(Y_i-\hat f(X_i))^2$$

The empirical permutation importance of the variable $X_j$ is defined by:
$$\hat I(X_j)=\frac{1}{n_{tree}}\sum _{t=1}^{n_{tree}}[\hat R(\hat f_t, \bar D^{tj}_n)-\hat R(\hat f_t, \bar D^{t}_n)]$$
The variable $X_j$ is permuted.

The NRFE algorithm can be summarized as follows:

1. Rank the variables using the permutation importance measure

2. Train a random forests 

3. Eliminate the less relevant variable(s) 

4. Repeat steps 2 and 3 until no further variables remain


The RFE algorithm can be summarized as follows:

1. Train a random forests 

2. Compute the permutation importance measure 

3. Eliminate the less relevant variable(s) 

4. Repeat steps 1 to 3 until no further variables remain

## Source R code

The source R code for _permudata_ is as follows:
```{r,eval=FALSE}
permudata=function(dt,i){
  n=nrow(dt)
  index=sample(n, size = n, replace = FALSE)
  temp=dt[index,i]
  dt[i]=temp
  return(dt)
}
```

The above code uses 'sample' to change the order of a certain variable in the given dataset.

The source R code for _rfpi_ is as follows:
```{r,eval=FALSE}
library(randomForest)
rfpi=function(dt,ntree){
dt=na.omit(dt)
n=nrow(dt)
p=ncol(dt)
temp=numeric(p-1)
set.seed(65432)
rf_ntree0=randomForest(dt[,1]~., data=dt, ntree=ntree,important=TRUE,proximity=TRUE)
mean0=mean(rf_ntree0$mse)
for (i in 2:p){
datai=permudata(dt,i)  
sol=randomForest(datai[,1]~., data=datai, ntree=ntree,important=TRUE,proximity=TRUE)
temp[i-1]=mean(sol$mse)
}
PI=temp-mean0
return(PI)
}
```

The above code calculates the permutation importance of variables with random forest algorithm. This function is bases on the former function 'permudata'.

The source R code for _NRFE_ is as follows:
```{r,eval=FALSE}
NRFE=function(dt,ntree){
PI=rfpi(dt,ntree) 
n=nrow(dt)
p=ncol(dt)
dele=order(PI)
err=numeric(p-1)
set.seed(32145)
mse0=mean(randomForest(dt[,1]~., data=dt, ntree=ntree,important=TRUE,proximity=TRUE)$mse)
err[1]=mse0
for (i in 2:(p-1)){
  delev=dele[1]+1
  dt=dt[,-delev]
  sol=randomForest(dt[,1]~., data=dt, ntree=ntree,important=TRUE,proximity=TRUE)
  err[i]=mean(sol$mse)
  PI=PI[-(delev-1)]
  dele=order(PI)
}
return(err)
}
```

The above code uses NRFE in random forests to select variables and calculate the error.

The source R code for _RFE_ is as follows:
```{r,eval=FALSE}
RFE=function(dt,ntree){
  n=nrow(dt)
  p=ncol(dt)
  err=numeric(p-1)
  set.seed(32145)
  mse0=mean(randomForest(dt[,1]~., data=dt, ntree=ntree,important=TRUE,proximity=TRUE)$mse)
  err[1]=mse0
  for (i in 2:(p-1)){
    PI=rfpi(dt,ntree) 
    dele=order(PI)
    delev=dele[1]+1
    dt=dt[-delev]
    sol=randomForest(dt[,1]~., data=dt, ntree=ntree,important=TRUE,proximity=TRUE)
    err[i]=mean(sol$mse)
  }
  return(err)
}
```

The above code uses RFE in random forests to select variables and calculate the error.

## Example

Use dataset "longley", the variables in which are highly correlated. Generate 1000 decision trees in the forest. Thus, we can see the difference in those two algorithms.

```{r,eval=TRUE}
library(StatComp20087)
dt=longley
ntree=1000
NRFE(dt,ntree)
RFE(dt,ntree)
```

From the result we can see that, the error of the model with different number of variables are different. This is because the NRFE algorithm uses the initial PI value for variable selection while the RFE algorithm updates the PI value ranking. As a result, they could choose different variables which makes the errors different.








